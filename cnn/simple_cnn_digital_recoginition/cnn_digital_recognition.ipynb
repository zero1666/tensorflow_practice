{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorFlow 使用简单的CNN识别手写数字"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 下载mnist数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "mnist 是一个手写数字的图片数据库,每一张图片都是0到9中的单个数字。每一张都是抗锯齿(Anti-aliasing)的灰度图,图片大小28x28像素,数字部分被归一化为20*20大小,位于图片的中间位置,保持了原来形状的比例.\n",
    "\n",
    "tensorflow 提供了一个input_data.py文件，专门用于下载mnist数据，通过下面的代码调用："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://s3.amazonaws.com/lasagne/recipes/datasets/mnist/\n",
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "from tensorflow.contrib.learn.python.learn.datasets.mnist import read_data_sets\n",
    "mnist = read_data_sets(\"MNIST_data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下载完后会在当前目录下看到 一个名为 'MNIST_data'的文件夹，里面是下载的mnist数据，四个压缩包。压缩包里的内容分别是：\n",
    "\n",
    "|文件\t                                     |内容|\n",
    "|---------------------------|----|\n",
    "|train-images-idx3-ubyte.gz\t|训练集图片 - 55000 张 训练图片, 5000 张 验证图片|\n",
    "|train-labels-idx1-ubyte.gz\t|训练集图片对应的数字标签|\n",
    "|t10k-images-idx3-ubyte.gz\t|测试集图片 - 10000 张 图片|\n",
    "|t10k-labels-idx1-ubyte.gz\t|测试集图片对应的数字标签|\n",
    "\n",
    "\n",
    ">因为网络问题无法访问 原来的 [SOURCE_URL](http://yann.lecun.com/exdb/mnist/), 所以根据[这里](https://stackoverflow.com/questions/33731875/tensorflow-ioerror-errno-socket-error-errno-104-connection-reset-by-peer)  的建议修改`anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py` 里的链接为'\n",
    "https://s3.amazonaws.com/lasagne/recipes/datasets/mnist/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(55000, 784) (55000, 10)\n",
      "(10000, 784) (10000, 10)\n",
      "(5000, 784) (5000, 10)\n"
     ]
    }
   ],
   "source": [
    "print(mnist.train.images.shape, mnist.train.labels.shape)\n",
    "print(mnist.test.images.shape, mnist.test.labels.shape)\n",
    "print(mnist.validation.images.shape,mnist.validation.labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.  实现CNN算法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "网络结构：两个卷积层+一个全连接层。比较的简单的一个网络结构，但CNN的要点都有。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def weight_variables(shape):\n",
    "    initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def bias_variables(shape):\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(initial)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 定义卷积和池化\n",
    "def conv2d(x, W):\n",
    "    return tf.nn.conv2d(x,W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "def max_pool_2x2(x):\n",
    "    return tf.nn.max_pool(x, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "定义网络结构"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#准备参数\n",
    "x = tf.placeholder(tf.float32, shape=[None, 784])\n",
    "y_ = tf.placeholder(tf.float32, shape=[None, 10])\n",
    "x_image = tf.reshape(x, [-1,28,28,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 第一卷积层\n",
    "w_conv1 = weight_variables([5,5,1,32])\n",
    "b_conv1 = bias_variables([32])\n",
    "h_conv1 = conv2d(x_image, w_conv1) + b_conv1\n",
    "h_conv1 = tf.nn.relu(h_conv1)\n",
    "h_pool1 = max_pool_2x2(h_conv1)\n",
    "\n",
    "# 第二卷积层\n",
    "w_conv2 = weight_variables([5,5,32,64])\n",
    "b_conv2 = bias_variables([64])\n",
    "h_conv2 = conv2d(h_pool1, w_conv2) + b_conv2\n",
    "h_conv2 = tf.nn.relu(h_conv2)\n",
    "h_pool2 = max_pool_2x2(h_conv2)\n",
    "\n",
    "# 第三层全连接层\n",
    "w_fc1 = weight_variables([7*7*64, 1024])\n",
    "b_fc1 = bias_variables([1024])\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "input_flat = tf.reshape(h_pool2, [-1, 7*7*64])\n",
    "h_fc1 = tf.nn.relu(tf.matmul(input_flat, w_fc1) + b_fc1)\n",
    "h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)\n",
    "\n",
    "# 第五 softmax 层 输出\n",
    "w_fc2 = weight_variables([1024, 10])\n",
    "b_fc2  = bias_variables([10])\n",
    "y_conv = tf.nn.softmax(tf.matmul(h_fc1_drop, w_fc2) + b_fc2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "定义 损失函数 和 优化器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_ * tf.log(y_conv), reduction_indices=[1]))\n",
    "train_step = tf.train.AdagradOptimizer(1e-4).minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "定义 准确率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "correct_prediction= tf.equal(tf.argmax(y_conv,1), tf.argmax(y_,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "开始训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step0, training accuracy 0.12\n",
      "step100, training accuracy 0.18\n",
      "step200, training accuracy 0.16\n",
      "step300, training accuracy 0.3\n",
      "step400, training accuracy 0.34\n",
      "step500, training accuracy 0.34\n",
      "step600, training accuracy 0.44\n",
      "step700, training accuracy 0.58\n",
      "step800, training accuracy 0.48\n",
      "step900, training accuracy 0.58\n",
      "step1000, training accuracy 0.72\n",
      "step1100, training accuracy 0.66\n",
      "step1200, training accuracy 0.64\n",
      "step1300, training accuracy 0.56\n",
      "step1400, training accuracy 0.6\n",
      "step1500, training accuracy 0.7\n",
      "step1600, training accuracy 0.7\n",
      "step1700, training accuracy 0.74\n",
      "step1800, training accuracy 0.64\n",
      "step1900, training accuracy 0.76\n",
      "step2000, training accuracy 0.7\n",
      "step2100, training accuracy 0.64\n",
      "step2200, training accuracy 0.8\n",
      "step2300, training accuracy 0.8\n",
      "step2400, training accuracy 0.8\n",
      "step2500, training accuracy 0.74\n",
      "step2600, training accuracy 0.78\n",
      "step2700, training accuracy 0.84\n",
      "step2800, training accuracy 0.76\n",
      "step2900, training accuracy 0.82\n",
      "step3000, training accuracy 0.8\n",
      "step3100, training accuracy 0.8\n",
      "step3200, training accuracy 0.84\n",
      "step3300, training accuracy 0.8\n",
      "step3400, training accuracy 0.7\n",
      "step3500, training accuracy 0.62\n",
      "step3600, training accuracy 0.6\n",
      "step3700, training accuracy 0.74\n",
      "step3800, training accuracy 0.78\n",
      "step3900, training accuracy 0.9\n",
      "step4000, training accuracy 0.9\n",
      "step4100, training accuracy 0.78\n",
      "step4200, training accuracy 0.78\n",
      "step4300, training accuracy 0.9\n",
      "step4400, training accuracy 0.86\n",
      "step4500, training accuracy 0.88\n",
      "step4600, training accuracy 0.88\n",
      "step4700, training accuracy 0.76\n",
      "step4800, training accuracy 0.9\n",
      "step4900, training accuracy 0.82\n",
      "step5000, training accuracy 0.8\n",
      "step5100, training accuracy 0.82\n",
      "step5200, training accuracy 0.76\n",
      "step5300, training accuracy 0.86\n",
      "step5400, training accuracy 0.8\n",
      "step5500, training accuracy 0.88\n",
      "step5600, training accuracy 0.76\n",
      "step5700, training accuracy 0.74\n",
      "step5800, training accuracy 0.86\n",
      "step5900, training accuracy 0.82\n",
      "step6000, training accuracy 0.84\n",
      "step6100, training accuracy 0.88\n",
      "step6200, training accuracy 0.92\n",
      "step6300, training accuracy 0.82\n",
      "step6400, training accuracy 0.92\n",
      "step6500, training accuracy 0.82\n",
      "step6600, training accuracy 0.98\n",
      "step6700, training accuracy 0.76\n",
      "step6800, training accuracy 0.86\n",
      "step6900, training accuracy 0.9\n",
      "step7000, training accuracy 0.82\n",
      "step7100, training accuracy 0.86\n",
      "step7200, training accuracy 0.88\n",
      "step7300, training accuracy 0.88\n",
      "step7400, training accuracy 0.9\n",
      "step7500, training accuracy 0.9\n",
      "step7600, training accuracy 0.88\n",
      "step7700, training accuracy 0.84\n",
      "step7800, training accuracy 0.86\n",
      "step7900, training accuracy 0.9\n",
      "step8000, training accuracy 0.84\n",
      "step8100, training accuracy 0.9\n",
      "step8200, training accuracy 0.86\n",
      "step8300, training accuracy 0.84\n",
      "step8400, training accuracy 0.88\n",
      "step8500, training accuracy 0.86\n",
      "step8600, training accuracy 0.98\n",
      "step8700, training accuracy 0.86\n",
      "step8800, training accuracy 0.84\n",
      "step8900, training accuracy 0.84\n",
      "step9000, training accuracy 0.76\n",
      "step9100, training accuracy 0.88\n",
      "step9200, training accuracy 0.9\n",
      "step9300, training accuracy 0.84\n",
      "step9400, training accuracy 0.86\n",
      "step9500, training accuracy 0.9\n",
      "step9600, training accuracy 0.86\n",
      "step9700, training accuracy 0.86\n",
      "step9800, training accuracy 0.88\n",
      "step9900, training accuracy 0.84\n",
      "step10000, training accuracy 0.92\n",
      "step10100, training accuracy 0.78\n",
      "step10200, training accuracy 0.92\n",
      "step10300, training accuracy 0.84\n",
      "step10400, training accuracy 0.8\n",
      "step10500, training accuracy 0.9\n",
      "step10600, training accuracy 0.9\n",
      "step10700, training accuracy 0.92\n",
      "step10800, training accuracy 0.9\n",
      "step10900, training accuracy 0.88\n",
      "step11000, training accuracy 0.88\n",
      "step11100, training accuracy 0.9\n",
      "step11200, training accuracy 0.82\n",
      "step11300, training accuracy 0.88\n",
      "step11400, training accuracy 0.94\n",
      "step11500, training accuracy 0.9\n",
      "step11600, training accuracy 0.88\n",
      "step11700, training accuracy 0.8\n",
      "step11800, training accuracy 0.96\n",
      "step11900, training accuracy 0.94\n",
      "step12000, training accuracy 0.86\n",
      "step12100, training accuracy 0.9\n",
      "step12200, training accuracy 0.86\n",
      "step12300, training accuracy 0.84\n",
      "step12400, training accuracy 0.92\n",
      "step12500, training accuracy 0.86\n",
      "step12600, training accuracy 0.94\n",
      "step12700, training accuracy 0.94\n",
      "step12800, training accuracy 0.9\n",
      "step12900, training accuracy 0.96\n",
      "step13000, training accuracy 0.94\n",
      "step13100, training accuracy 0.86\n",
      "step13200, training accuracy 0.88\n",
      "step13300, training accuracy 0.92\n",
      "step13400, training accuracy 0.86\n",
      "step13500, training accuracy 0.94\n",
      "step13600, training accuracy 0.94\n",
      "step13700, training accuracy 0.92\n",
      "step13800, training accuracy 0.9\n",
      "step13900, training accuracy 0.84\n",
      "step14000, training accuracy 0.8\n",
      "step14100, training accuracy 0.78\n",
      "step14200, training accuracy 0.8\n",
      "step14300, training accuracy 0.9\n",
      "step14400, training accuracy 0.94\n",
      "step14500, training accuracy 0.92\n",
      "step14600, training accuracy 0.9\n",
      "step14700, training accuracy 0.88\n",
      "step14800, training accuracy 0.92\n",
      "step14900, training accuracy 0.9\n",
      "step15000, training accuracy 0.82\n",
      "step15100, training accuracy 0.98\n",
      "step15200, training accuracy 0.94\n",
      "step15300, training accuracy 0.88\n",
      "step15400, training accuracy 0.84\n",
      "step15500, training accuracy 0.96\n",
      "step15600, training accuracy 0.92\n",
      "step15700, training accuracy 0.82\n",
      "step15800, training accuracy 0.94\n",
      "step15900, training accuracy 0.9\n",
      "step16000, training accuracy 0.9\n",
      "step16100, training accuracy 0.96\n",
      "step16200, training accuracy 0.86\n",
      "step16300, training accuracy 0.88\n",
      "step16400, training accuracy 0.92\n",
      "step16500, training accuracy 0.96\n",
      "step16600, training accuracy 1\n",
      "step16700, training accuracy 0.92\n",
      "step16800, training accuracy 0.86\n",
      "step16900, training accuracy 0.86\n",
      "step17000, training accuracy 0.86\n",
      "step17100, training accuracy 0.88\n",
      "step17200, training accuracy 0.9\n",
      "step17300, training accuracy 0.94\n",
      "step17400, training accuracy 0.9\n",
      "step17500, training accuracy 0.86\n",
      "step17600, training accuracy 0.88\n",
      "step17700, training accuracy 0.98\n",
      "step17800, training accuracy 0.88\n",
      "step17900, training accuracy 0.88\n",
      "step18000, training accuracy 0.92\n",
      "step18100, training accuracy 0.96\n",
      "step18200, training accuracy 0.84\n",
      "step18300, training accuracy 0.92\n",
      "step18400, training accuracy 0.92\n",
      "step18500, training accuracy 0.94\n",
      "step18600, training accuracy 0.88\n",
      "step18700, training accuracy 0.96\n",
      "step18800, training accuracy 0.9\n",
      "step18900, training accuracy 0.86\n",
      "step19000, training accuracy 0.92\n",
      "step19100, training accuracy 0.84\n",
      "step19200, training accuracy 0.88\n",
      "step19300, training accuracy 0.94\n",
      "step19400, training accuracy 0.96\n",
      "step19500, training accuracy 0.9\n",
      "step19600, training accuracy 0.92\n",
      "step19700, training accuracy 0.9\n",
      "step19800, training accuracy 0.92\n",
      "step19900, training accuracy 0.88\n"
     ]
    }
   ],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "tf.global_variables_initializer().run()\n",
    "batch_size=50\n",
    "\n",
    "for i in range(batch_size*400):\n",
    "    batch = mnist.train.next_batch(batch_size)\n",
    "    if i%100 == 0:\n",
    "        train_accuracy = accuracy.eval(feed_dict={x:batch[0], y_:batch[1], keep_prob:1.0})\n",
    "        print(\"step%d, training accuracy %g\"%(i, train_accuracy))\n",
    "        \n",
    "    train_step.run({x:batch[0], y_: batch[1], keep_prob:0.5})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'accuracy' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-2339b9d83cd0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mmnist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmnist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeep_prob\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'accuracy' is not defined"
     ]
    }
   ],
   "source": [
    "print(accuracy.eval({x:mnist.test.images, y_: mnist.test.labels, keep_prob:1}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
